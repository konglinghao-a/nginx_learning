# 6、场景实践-负载均衡

## 6-1 负载均衡基础原理

- nginx 将请求代理到多台服务器去执行，就称之为负载均衡
- 这里的多台服务器通常**承担一样的功能任务**

## 6-2 配置实现 nginx 对上游服务器负载均衡

定义 3 台**上游服务器**（基于端口的虚拟主机）：

`/etc/nginx/conf.d/app_server.conf`

```shell
server {
	listen 8020;
	location / {
		return 200 'Return Result For Server 8020\n';
	}
}
server {
	listen 8021;
	location / {
		return 200 'Return Result For Server 8021\n';
	}
}
server {
	listen 8022;
	location / {
		return 200 'Return Result For Server 8022\n'
	}
}
```

定义 nginx 服务器用于负载均衡：

`/opt/nginx/conf.d/load_balance.conf`

```shell
upstream demo_server {
	# 三个 server 都没有加任何参数的情况下
	server 192.168.1.20:8020;
	server 192.168.1.20:8021;
	server 192.168.1.20:8022;
}

server {
	listen 80;
	server_name: balance.kutian.edu;
	
	location /balance/ {
		proxy_pass http://demo_server;
	}
}
```

```shell
# 定义好服务器以后，接下来就能进行一些列操作了
/opt/nginx/sbin/nginx -s reload
ss -nlt # 查看端口是不是监听着
vim /etc/hosts # 配置本地域名和 ip 的映射

# 对域名进行请求：
curl balance.kutian.edu/balance	# Return Result For Server 8020
curl balance.kutian.edu/balance	# Return Result For Server 8021
curl balance.kutian.edu/balance	# Return Result For Server 8022
curl balance.kutian.edu/balance	# Return Result For Server 8020
curl balance.kutian.edu/balance	# Return Result For Server 8020

# 可见不加任何参数的情况下，nginx 大致来说是按照定义的顺序来分配请求给上游服务器的（这是采用轮询的方式）
```

接下来试一试，在 upstream 中定义 server 时加上权重

`/opt/nginx/conf.d/load_balance.conf`

```shell
upstream demo_server {
	server 192.168.1.20:8020 weight=2;
	server 192.168.1.20:8021 weight=1;
}

server {
	listen 80;
	server_name: balance.kutian.edu;
	
	location /balance/ {
		proxy_pass http://demo_server;
	}
}
```

```shell
# 对域名进行请求：
curl balance.kutian.edu/balance	# Return Result For Server 8020
curl balance.kutian.edu/balance	# Return Result For Server 8020
curl balance.kutian.edu/balance	# Return Result For Server 8021
curl balance.kutian.edu/balance	# Return Result For Server 8020
curl balance.kutian.edu/balance	# Return Result For Server 8021

# 可见加了权重的情况下，也并不是访问了权重为 2 的，后面访问的一定是权重为 1 的；分配权重指的是，在量比较大的情况下，权重高的总体来说会先被分配。
```

## 6-3 负载均衡算法 — 哈希算法

### 哈希算法概念

- 哈希算法是将任意长度的二进制值映射为较短的**固定长度的二进制值**，这个小的二进制值我们称之为哈希值。
- 散落明文到哈希值的映射是不可逆的

![](./media/17.png)

如果文件的内容不变，哈希值是不会变的。这样的用处就是，数据发送给服务器的时候在网络中是分组转发的，如果到了服务器拼接了之后文件内容发生了改变（比如丢包），那么哈希值就会发生变化；可以通过比较哈希值来判断文件是否发生了改变。

### hash 指令

- 语法：hash key [ consistent ]：key 的意思是根据哪个 key（比如挑选某个请求头信息，或者 ip） 来进行 hash 运算；
- 默认值：无
- upstream

### 演示一波

定义**上游服务器**：

`/etc/nginx/conf.d/app_server.conf`

```shell
server {
	listen 10020;
	location / {
		return 200 'Return Result For Server 10020\n';
	}
}
server {
	listen 10010;
	location / {
		return 200 'Return Result For Server 10010\n';
	}
}
```

配置 nginx 来进行反向代理

`/opt/nginx/conf.d/load_balance.conf`

```shell
upstream demo_server_1 {
	hash $request_uri; # 使用了 hash 算法之后，如果你的 uri 不发生变化，那么就会永远给你分配那一台后端应用程序服务器，不会发生变化。
	server 192.168.1.20:10020;
	server 192.168.1.20:10010;
}
server {
	listen 80;
	server_name balance_hash.kutian.edu;
	
	location / {
		proxy_pass http://demo_server_1;
	}
}
```

```shell
# 测试一波
curl balance_hash.kutian.edu/index.html # Return Result For Server 10020
curl balance_hash.kutian.edu/index.html # Return Result For Server 10020
curl balance_hash.kutian.edu/index.html # Return Result For Server 10020
# 由此发现 uri 没发生变化，那么分配的应用程序服务器也不变

curl balance_hash.kutian.edu/test/index.html # Return Result For Server 10010
curl balance_hash.kutian.edu/test/index.html # Return Result For Server 10010
curl balance_hash.kutian.edu/test/index.html # Return Result For Server 10010
# uri 发生改变，分配的应用程序发生了变化

```

hash 算法在这里的应用主要是缓存的方面比较多。

## 6-4 负载均衡算法 — ip_hash 算法

hash 算法可以根据不同的 key 来进行 hash 运算。但是有些时候我们就想根据特定的值（比如 ip，亦或是请求头的某些具体行）来进行 hash 运算，这时候就可以看看 ip_hash 算法。

### ip_hash 指令

- 语法：ip_hash;
- 默认值：无
- 上下文：upstream

演示一波

`/opt/nginx/conf.d/load_balance.conf`

```shell
upstream demo_server_1 {
	ip_hash; # 如果你的 ip 地址不变，那么它永远会给你分配那固定的一台后端应用程序服务器
	server 192.168.1.20:10020;
	server 192.168.1.20:10010;
}
server {
	listen 80;
	server_name balance_hash.kutian.edu;
	
	location / {
		proxy_pass http://demo_server_1;
	}
}
```

```shell
# 测试一波
# ip 地址不变，nginx 给它分配的服务器就不会变
curl balance_hash.kutian.edu/index.html # Return Result For Server 10020
curl balance_hash.kutian.edu/index.html # Return Result For Server 10020
curl balance_hash.kutian.edu/index.html # Return Result For Server 10020
```

某些客户端在请求完之后可能会有 cookie 信息，服务器保存了 session 信息，固定分配一台服务器的话 session 信息就不会丢失，利于 session 信息的保持。

## 6-5 负载均衡算法 — 最少连接数算法

之前使用 weight 来进行轮询，或者是使用 hash / ip_hash，它都存在一个问题，那就是都没有对应用服务器当前的**负载状况**进行考虑。

### 最少连接数算法

- 从上游服务器中挑选一台当前已建立连接数最少的，然后分配请求。
- 极端情况下（每个上有服务器的连接数都相同）退化为轮询算法

### least_conn 指令

nginx 已内置模块：ngx_http_upstream_least_conn_module；禁用的话就通过：--without-http_upstream_least_conn_module。

- 语法：least_conn;
- 默认值：无
- 上下文：upstream

### 关于多 worker 子进程的问题

接下来还需要思考一个问题：如果只有一个 worker 子进程，那么客户端来了请求之后直接进行分配，它总是能拿到后端应用程序服务器的连接信息，比如咨询一下第一个后端服务器的请求连接数，然后再咨询第二个后端服务器的请求连接数...最后拿到了每个服务器的连接数状态，然后就能进行分配了。

**但是，**nginx 通常有多个 worker 子进程，用户的请求每次可能会分配到不同的 worker 子进程，比如第一次到达第一个 worker 子进程，第二次就到达第二个 worker 子进程。对于多 worker 子进程下启动最小连接数算法的情况下，worker 子进程们如何知道应用服务器处理的请求连接数状态呢？在 nginx 上开辟出一块内存空间，这一块内存空间是作为共享内存来使用的。也就是说 worker 子进程在处理请求的时候，它都会把后端服务器的连接数，失败数等服务器状态保存在这块共享内存中，这样不同的 worker 子进程在处理请求的时候就能通过这个共享内存知道服务器的信息，从而来分配请求。

![](./media/18.png)

### zone 指令

- 语法：zone name [ size ];   指定共享内存，也可以给它分配空间
- 默认值：无
- 上下文：upstream

`/opt/nginx/conf.d/load_balance.conf`

```shell
upstream demo_server_1 {
	zone test 10M; # 分配共享内存
	least_conn; # 指定最小连接数算法
	server 192.168.1.20:10020;
	server 192.168.1.20:10010;
}
server {
	listen 80;
	server_name balance_hash.kutian.edu;
	
	location / {
		proxy_pass http://demo_server_1;
	}
}
```

## 6-6 负载均衡场景下 nginx 针对上游服务器返回异常时的容错机制

nginx 将请求分配给后端应用程序服务器 1 的时候，可能这个服务器出现了错误并返回了错误信息，那么这个时候 nginx 能否再将这个请求分配给别的后端应用程序服务器呢？

### 指令

- **proxy_next_upstream**：某一台应用程序服务器出现错误，无法处理请求等情况，nginx 会将请求再次分配给别的应用程序服务器。

  - 语法：proxy_next_upstream error | timeout | invalid_header | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | http_429 | non_idempotent | off

  - 默认值：**proxy_next_upstream error timeout**;  这里就要注意了，它默认就是要转发的

  - 上下文：http、server、location

  - 参数可选值：

    | 可选参数       | 含义                                               |
    | -------------- | -------------------------------------------------- |
    | error          | 向上游服务器传输请求或读取响应头发生错误           |
    | timeout        | 向上游服务器传输请求或读取响应头发生超时           |
    | invalid_header | 上游服务器返回无效的响应                           |
    | http_500       | 服务器内部错误                                     |
    | http_502       | 从远端服务器收到个无效响应                         |
    | http_503       | 系统维护，无法请求                                 |
    | http_504       | 充当网关或代理的服务器，未及时从远端服务器获取请求 |
    | http_403       | 服务器理解请求客户端的请求，但是拒绝执行此请求     |
    | http_404       | 无法找到资源                                       |
    | http_429       | 请求太多了！                                       |
    | non_idempotent | 非幂等请求失败时是否需要转发下一台上游服务器       |
    | off            | 禁用请求失败转发功能                               |

  - 有些时候这个指令是比较**危险的**，比如像充值的场景，如果服务器执行了充值的操作以后，没有及时将响应返回给 nginx，那么 nginx 会重新将请求转发给别的后端服务器，这样就会执行了重复充值。

- **proxy_next_upstream_timeout**：如果一台应用程序服务器发生错误，那么等待一段时间后，再把请求转发给另外一台应用程序服务器，这个等待的时间就可以在这里进行定义。**如果是 0，**意思是无限制地等待。
  - 语法：proxy_next_upstream_timeout time;
  - 默认值：proxy_next_upstream_timeout 0;
  - 上下文：http、server、location

- **proxy_next_upstream_tries**：如果服务器1不行，那么就调度到服务器2；如果服务器2不行，那么就调度到服务器3...... 这个调度的次数就可以通过这个指令来设置。**如果是0**，那么可以一直调度下去。
  - 语法：proxy_next_upstream_tries number;
  - 默认值：proxy_next_upstream_tries 0;
  - 上下文：http、server、location

- **proxy_intercept_errors**：上游返回响应码大于 300 时，是直接将上游响应返回客户端还是按照 error_page 处理
  - 用法：proxy_intercept_errors on | off;
  - 默认值：proxy_intercept_errors on;   如果是 on，那就会返回 error_page
  - 上下文：http、server、location

### 用法

定义**上游服务器**：

`/etc/nginx/conf.d/app_server.conf`

```shell
server {
	listen 4040;
	location / {
		return 200 'Return Result For Server 4040\n';
	}
}
server {
	listen 4050;
	location / {
		return 200 'Return Result For Server 4050\n';
	}
}
```

配置 nginx 来进行反向代理

`/opt/nginx/conf.d/load_balance.conf`

```shell
upstream test_tolerant_server {
	server 192.168.1.20:4040;
	server 192.168.1.20:4050;
}
server {
	listen 80;
	
	location /test {
		proxy_pass http://test_tolerant_server;
		# proxy_next_upstream timeout error; # proxy_next_upstream 默认是有值的，所以不写的时候，即使一台服务器宕机了，可以把请求分配给另一台服务器。
	}
}
```

